{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Maldive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Preparatory stage\n",
    "\n",
    "## Set up the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from itertools import tee\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from trefle.fitness_functions.output_thresholder import round_to_cls\n",
    "from trefle.trefle_classifier import TrefleClassifier\n",
    "\n",
    "from trefle_engine import TrefleFIS\n",
    "\n",
    "\n",
    "\n",
    "import libraries.measures_calculation\n",
    "import libraries.trefle_project\n",
    "import libraries.interpretability_methods\n",
    "import libraries.interpretability_plots\n",
    "import libraries.results_plot\n",
    "from libraries.model_var import ModelVar\n",
    "from libraries.model_train_cv import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset\n",
    "<br>\n",
    "The first step of the ML process is to split our dataset into training and test parts (subsets). <br> \n",
    "<ul>\n",
    "    <li>You must indicate the path of your original dataset</li>\n",
    "    <li>You must indicate the path where you want to save the training part</li>\n",
    "    <li>You must indicate the path where you want to save the test part</li>\n",
    "</ul>\n",
    "<br>When a plot is \"open\" you need to \"shut it down\" in order to plot the others (button on the upper corner right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73, 1703) (73, 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5f1fbfe9794c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_load\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Herbicide'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m7\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3848\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5f1fbfe9794c>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_load\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Herbicide'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m7\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "#Read Dataset\n",
    "#Indicate the path of the original DS HERE:\n",
    "#--------------------\n",
    "csv_path_file_name = './datasets/ProtistAmpliconSequenceVariants_ASV_2016.csv'\n",
    "#--------------------\n",
    "\n",
    "data_load = pd.read_csv(csv_path_file_name, sep = ';')\n",
    "target_load = pd.read_csv('./datasets/Env_2016.csv', sep = ';')\n",
    "\n",
    "#Remove the 0's columns\n",
    "data_load = data_load.loc[:, (data_load != 0).any(axis=0)]\n",
    "data_load = data_load.drop(data_load.columns[0], axis=1)\n",
    "\n",
    "target_load = target_load[['Herbicide']]\n",
    "\n",
    "print(data_load.shape, target_load.shape)\n",
    "\n",
    "X = data_load\n",
    "y = target_load['Herbicide'].apply(lambda x: 1 if x ==\"yes\" else 0)\n",
    "\n",
    "\n",
    "#Split it into train test DS\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, stratify=y, random_state=42, test_size=0.33)\n",
    "\n",
    "plt.hist(y_train, bins='auto', label='Train')\n",
    "\n",
    "plt.hist(y_test, bins='auto', label='Test')\n",
    "plt.title(\"Train test Split\")\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Quantity')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Save separetly in training and test\n",
    "#It is important to save the training and test sets (we will use the test in the second part)\n",
    "y_train_modify = np.reshape(y_train, (-1, 1))\n",
    "train_dataset = np.append(X_train, y_train_modify, axis=1)\n",
    "\n",
    "y_test_modify = np.reshape(y_test, (-1, 1))\n",
    "test_dataset = np.append(X_test, y_test_modify, axis=1)\n",
    "\n",
    "#This indicates to numpy how to format the output (you can create a function for a larger number of variables...)\n",
    "#format_values = '%1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %1.3f %i'\n",
    "\n",
    "\n",
    "#Indicate the path where you want to save the training and test part DS HERE:\n",
    "#--------------------\n",
    "path_train_csv = './datasets/data_project_train_v2.csv'\n",
    "path_test_csv = './datasets/data_project_test_v2.csv'\n",
    "#--------------------\n",
    "np.savetxt(path_train_csv, train_dataset, delimiter=\";\")\n",
    "np.savetxt(path_test_csv, test_dataset, delimiter=\";\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"background-color:red;color:white\">Question 1</b>:  Comment the plot above (include it into your report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trefle Classifier\n",
    "<br> In the code below you have a description of the (fuzzy logic-based) classifier that we use along this labo, the theory is provided in the slides of the cours. <br>\n",
    "Don't forget to change, if necessary, the number of generations (iterations) of your algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the fitness function we want to use\n",
    "def fit(y_true, y_pred):\n",
    "    # Here no need to threshold y_pred because we are using a regression\n",
    "    # metric\n",
    "    return -mean_squared_error(y_true, y_pred)\n",
    "\n",
    "#Initialize our classsifier TREFLE\n",
    "clf = TrefleClassifier(\n",
    "    n_rules=60,\n",
    "    n_classes_per_cons=[2],  # In regression, there is no class (i.e. 0)\n",
    "    n_labels_per_mf=3,  # use 3 labels LOW, MEDIUM, HIGH\n",
    "    default_cons=[0],  # default rule yield the class 0\n",
    "    n_max_vars_per_rule=12,  # WBCD dataset has 30 variables, here we force\n",
    "    # to use a maximum of 3 variables per rule\n",
    "    # to have a better interpretability\n",
    "    # In total we can have up to 3*4=12 different variables\n",
    "    # for a fuzzy system\n",
    "    \n",
    "    #Change here the number of generations (if necessary)\n",
    "    n_generations=50,\n",
    "    fitness_function=fit,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and predicting with Trefle\n",
    "<br> Below you have a simple example of how to:<br>\n",
    "<ul>\n",
    "    <li>train a model and make a prediction with it</li>\n",
    "    <li>save the model in a file</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tspecies\tstd        \tmin      \tavg      \tmax      \tavg_hof  \n",
      "1  \tsp1    \t1.11022e-16\t-0.333333\t-0.333333\t-0.333333\t-0.331641\n",
      "1  \tsp2    \t0.0377928  \t-0.568877\t-0.333303\t-0.3125  \t-0.3125  \n",
      "2  \tsp1    \t0          \t-0.3125  \t-0.3125  \t-0.3125  \t-0.3125  \n",
      "2  \tsp2    \t0.031615   \t-0.53191 \t-0.330616\t-0.310664\t-0.312423\n",
      "3  \tsp1    \t0.00296192 \t-0.3125  \t-0.311603\t-0.291667\t-0.309585\n",
      "3  \tsp2    \t0.0351725  \t-0.53191 \t-0.326931\t-0.216172\t-0.297097\n",
      "4  \tsp1    \t0.0119979  \t-0.292685\t-0.231055\t-0.209661\t-0.222015\n",
      "4  \tsp2    \t0.0912855  \t-0.6875  \t-0.334632\t-0.209661\t-0.220406\n",
      "5  \tsp1    \t0.00844332 \t-0.272161\t-0.212696\t-0.20426 \t-0.208825\n",
      "5  \tsp2    \t0.0656834  \t-0.546778\t-0.30904 \t-0.200075\t-0.207447\n",
      "6  \tsp1    \t0.00740319 \t-0.240806\t-0.206924\t-0.199422\t-0.202415\n",
      "6  \tsp2    \t0.110925   \t-0.684815\t-0.32008 \t-0.199422\t-0.201049\n",
      "7  \tsp1    \t0.0130649  \t-0.272161\t-0.206474\t-0.198095\t-0.199256\n",
      "7  \tsp2    \t0.081197   \t-0.604167\t-0.300932\t-0.198095\t-0.198794\n",
      "8  \tsp1    \t0.0172896  \t-0.31135 \t-0.204661\t-0.198095\t-0.198095\n",
      "8  \tsp2    \t0.0938241  \t-0.666667\t-0.311383\t-0.192326\t-0.197854\n",
      "9  \tsp1    \t0.0193822  \t-0.333333\t-0.20541 \t-0.186081\t-0.196478\n",
      "9  \tsp2    \t0.0914586  \t-0.647708\t-0.30652 \t-0.186081\t-0.19568 \n",
      "10 \tsp1    \t0.0192079  \t-0.273029\t-0.197566\t-0.179757\t-0.185245\n",
      "10 \tsp2    \t0.0821872  \t-0.57643 \t-0.31986 \t-0.179757\t-0.184684\n",
      "11 \tsp1    \t0.0182611  \t-0.286311\t-0.189603\t-0.177741\t-0.179527\n",
      "11 \tsp2    \t0.0815291  \t-0.583333\t-0.30723 \t-0.177741\t-0.179191\n",
      "12 \tsp1    \t0.0150296  \t-0.248942\t-0.18415 \t-0.172924\t-0.177463\n",
      "12 \tsp2    \t0.0759154  \t-0.565301\t-0.29827 \t-0.172924\t-0.177463\n",
      "13 \tsp1    \t0.0164292  \t-0.259264\t-0.18091 \t-0.172681\t-0.172904\n",
      "13 \tsp2    \t0.104082   \t-0.6875  \t-0.31116 \t-0.155424\t-0.172164\n",
      "14 \tsp1    \t0.0278486  \t-0.290671\t-0.16829 \t-0.145261\t-0.152985\n",
      "14 \tsp2    \t0.0749844  \t-0.474438\t-0.289668\t-0.144523\t-0.152218\n",
      "15 \tsp1    \t0.0165064  \t-0.229167\t-0.153884\t-0.144523\t-0.145182\n",
      "15 \tsp2    \t0.076486   \t-0.480632\t-0.28354 \t-0.144523\t-0.145179\n",
      "16 \tsp1    \t0.018577   \t-0.223964\t-0.154806\t-0.139775\t-0.143671\n",
      "16 \tsp2    \t0.0938144  \t-0.614099\t-0.295456\t-0.139775\t-0.143373\n",
      "17 \tsp1    \t0.0260018  \t-0.247843\t-0.152367\t-0.136606\t-0.139311\n",
      "17 \tsp2    \t0.0898559  \t-0.604167\t-0.281305\t-0.136606\t-0.139179\n",
      "18 \tsp1    \t0.0178808  \t-0.24349 \t-0.146169\t-0.136199\t-0.136589\n",
      "18 \tsp2    \t0.0776365  \t-0.482856\t-0.283429\t-0.136199\t-0.136572\n",
      "19 \tsp1    \t0.0233014  \t-0.285573\t-0.148713\t-0.135494\t-0.136169\n",
      "19 \tsp2    \t0.0897993  \t-0.504489\t-0.274581\t-0.135494\t-0.13614 \n",
      "20 \tsp1    \t0.0210439  \t-0.243083\t-0.147683\t-0.135494\t-0.135494\n",
      "20 \tsp2    \t0.0821849  \t-0.591114\t-0.288356\t-0.134684\t-0.13546 \n",
      "21 \tsp1    \t0.00948553 \t-0.188021\t-0.141495\t-0.135091\t-0.135444\n",
      "21 \tsp2    \t0.077809   \t-0.389815\t-0.283026\t-0.135091\t-0.135427\n",
      "22 \tsp1    \t0.0174147  \t-0.229147\t-0.14368 \t-0.134142\t-0.134955\n",
      "22 \tsp2    \t0.0868851  \t-0.500143\t-0.294869\t-0.134142\t-0.134916\n",
      "23 \tsp1    \t0.0201186  \t-0.241829\t-0.144877\t-0.133735\t-0.134125\n",
      "23 \tsp2    \t0.0826253  \t-0.471688\t-0.283699\t-0.133735\t-0.134108\n",
      "24 \tsp1    \t0.00960608 \t-0.178634\t-0.139051\t-0.132004\t-0.133663\n",
      "24 \tsp2    \t0.0887404  \t-0.489176\t-0.279377\t-0.132004\t-0.13359 \n",
      "25 \tsp1    \t0.0197578  \t-0.24933 \t-0.140364\t-0.132004\t-0.132004\n",
      "25 \tsp2    \t0.0781002  \t-0.416667\t-0.27849 \t-0.132004\t-0.132004\n",
      "26 \tsp1    \t0.0159349  \t-0.197127\t-0.141822\t-0.132004\t-0.132004\n",
      "26 \tsp2    \t0.0819462  \t-0.460491\t-0.286425\t-0.132004\t-0.132004\n",
      "27 \tsp1    \t0.0194075  \t-0.243083\t-0.145613\t-0.132004\t-0.132004\n",
      "27 \tsp2    \t0.0883134  \t-0.480119\t-0.282932\t-0.132004\t-0.132004\n",
      "28 \tsp1    \t0.0158433  \t-0.218042\t-0.138834\t-0.132004\t-0.132004\n",
      "28 \tsp2    \t0.0922357  \t-0.583333\t-0.295375\t-0.132004\t-0.132004\n",
      "29 \tsp1    \t0.0160793  \t-0.203505\t-0.141656\t-0.132004\t-0.132004\n",
      "29 \tsp2    \t0.0889791  \t-0.509685\t-0.294708\t-0.132004\t-0.132004\n",
      "30 \tsp1    \t0.0149562  \t-0.212506\t-0.142999\t-0.132004\t-0.132004\n",
      "30 \tsp2    \t0.0784044  \t-0.453776\t-0.286562\t-0.132004\t-0.132004\n",
      "31 \tsp1    \t0.0205315  \t-0.227384\t-0.144318\t-0.132004\t-0.132004\n",
      "31 \tsp2    \t0.0866437  \t-0.479491\t-0.271456\t-0.132004\t-0.132004\n",
      "32 \tsp1    \t0.0182154  \t-0.219939\t-0.142996\t-0.132004\t-0.132004\n",
      "32 \tsp2    \t0.0890807  \t-0.535242\t-0.278002\t-0.132004\t-0.132004\n",
      "33 \tsp1    \t0.0175438  \t-0.219068\t-0.142642\t-0.132004\t-0.132004\n",
      "33 \tsp2    \t0.079825   \t-0.538604\t-0.299722\t-0.132004\t-0.132004\n",
      "34 \tsp1    \t0.0156892  \t-0.221993\t-0.140962\t-0.132004\t-0.132004\n",
      "34 \tsp2    \t0.0837814  \t-0.479167\t-0.274508\t-0.132004\t-0.132004\n",
      "35 \tsp1    \t0.0184126  \t-0.195438\t-0.144137\t-0.132004\t-0.132004\n",
      "35 \tsp2    \t0.0843421  \t-0.479167\t-0.284382\t-0.132004\t-0.132004\n",
      "36 \tsp1    \t0.0166921  \t-0.217345\t-0.140616\t-0.132004\t-0.132004\n",
      "36 \tsp2    \t0.0868372  \t-0.5625  \t-0.294728\t-0.132004\t-0.132004\n",
      "37 \tsp1    \t0.0187206  \t-0.203904\t-0.143932\t-0.132004\t-0.132004\n",
      "37 \tsp2    \t0.0863799  \t-0.457988\t-0.272096\t-0.132004\t-0.132004\n",
      "38 \tsp1    \t0.0195598  \t-0.233988\t-0.141106\t-0.132004\t-0.132004\n",
      "38 \tsp2    \t0.0916116  \t-0.513707\t-0.291828\t-0.132004\t-0.132004\n",
      "39 \tsp1    \t0.0174199  \t-0.221623\t-0.141302\t-0.132004\t-0.132004\n",
      "39 \tsp2    \t0.0774006  \t-0.458333\t-0.281612\t-0.132004\t-0.132004\n",
      "40 \tsp1    \t0.0235514  \t-0.232857\t-0.145415\t-0.132004\t-0.132004\n",
      "40 \tsp2    \t0.0880146  \t-0.5625  \t-0.289627\t-0.132004\t-0.132004\n",
      "41 \tsp1    \t0.0246018  \t-0.235552\t-0.144349\t-0.132004\t-0.132004\n",
      "41 \tsp2    \t0.0883118  \t-0.566406\t-0.285997\t-0.132004\t-0.132004\n",
      "42 \tsp1    \t0.0158529  \t-0.218638\t-0.143242\t-0.132004\t-0.132004\n",
      "42 \tsp2    \t0.0929887  \t-0.556477\t-0.289742\t-0.132004\t-0.132004\n",
      "43 \tsp1    \t0.0259993  \t-0.220052\t-0.150237\t-0.132004\t-0.132004\n",
      "43 \tsp2    \t0.0849491  \t-0.527823\t-0.286782\t-0.132004\t-0.132004\n",
      "44 \tsp1    \t0.0224458  \t-0.238677\t-0.144073\t-0.132004\t-0.132004\n",
      "44 \tsp2    \t0.0775243  \t-0.444353\t-0.283289\t-0.132004\t-0.132004\n",
      "45 \tsp1    \t0.0256802  \t-0.251693\t-0.145592\t-0.132004\t-0.132004\n",
      "45 \tsp2    \t0.0975645  \t-0.5401  \t-0.284086\t-0.132004\t-0.132004\n",
      "46 \tsp1    \t0.02108    \t-0.222527\t-0.143394\t-0.132004\t-0.132004\n",
      "46 \tsp2    \t0.0923484  \t-0.491507\t-0.284717\t-0.128372\t-0.131852\n",
      "47 \tsp1    \t0.0215345  \t-0.222045\t-0.139555\t-0.121935\t-0.127576\n",
      "47 \tsp2    \t0.0947295  \t-0.60713 \t-0.268276\t-0.121935\t-0.127576\n",
      "48 \tsp1    \t0.0216911  \t-0.21837 \t-0.133965\t-0.115391\t-0.121157\n",
      "48 \tsp2    \t0.089671   \t-0.529473\t-0.286058\t-0.115391\t-0.121157\n",
      "49 \tsp1    \t0.0114863  \t-0.162242\t-0.125249\t-0.114159\t-0.115382\n",
      "49 \tsp2    \t0.110348   \t-0.666667\t-0.299552\t-0.114159\t-0.115382\n",
      "50 \tsp1    \t0.0148185  \t-0.183182\t-0.122868\t-0.11175 \t-0.11385 \n",
      "50 \tsp2    \t0.0904196  \t-0.583333\t-0.260505\t-0.11175 \t-0.11375 \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f1_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-fe60adeb7b93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Evaluate accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Score on test set: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f1_score' is not defined"
     ]
    }
   ],
   "source": [
    "#Make a train\n",
    "y_sklearn = np.reshape(y_train, (-1, 1))\n",
    "\n",
    "clf.fit(X_train, y_sklearn)\n",
    "# Make predictions\n",
    "y_pred = clf.predict_classes(X_test)\n",
    "\n",
    "clf.print_best_fuzzy_system()\n",
    "\n",
    "# Evaluate accuracy\n",
    "score = f1_score(y_test, y_pred)\n",
    "print(\"Score on test set: {:.3f}\".format(score))\n",
    "\n",
    "tff = clf.get_best_fuzzy_system_as_tff()\n",
    "\n",
    "# Export: save the fuzzy model to disk\n",
    "with open(\"my_saved_model_trefle.tff\", mode=\"w\") as f:\n",
    "    f.write(tff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Model-parameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the fitness function have been defined, we may search values for other parameters of the algorithm. In this part we will focus on the size (complexity) of the model, represented by the number of rules and the number of variables per rule.\n",
    "\n",
    "<b style=\"background-color:red;color:white\">Question 5</b>: Explain what are the implications of these two parameters (i.e., number of rules and number of variables per rule) on the models, in terms of both performance and interpretability.\n",
    "<br>\n",
    "<b style=\"background-color:red;color:white\">Question 6</b>: If you have setted your algorithm up to use 6 rules and 5 variables per rule on a dataset composeed of 100 features, how many features could be used at most by a model?\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Important:** Before continuing, don't forget to set the right weights for sensitivity, specificity, and RMSE!\n",
    "\n",
    "### Coarse estimation of the model size\n",
    "Not knowing the complexity of the required models, we must first roughly estimate them. This is done by exploring a relatively large range of model sizes. Performing a grid search (i.e., exploring both parameters simultaneously) would be the best approach, but that may be extremely costly and time consuming. Instead, we will explore one of the parameters, the number of rules. \n",
    "\n",
    "** Note:** Before performing the experiments, don't forget to set the values for the <b>rules_number_vec</b>. They represent the number of rules, pay attention to the size of the model. Don't change the value of 'var_per_rule_fix'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"background-color:red;color:white\">Question 7</b>: In your opinion, why did we decide to first explore the number of rules instead of the number of variables per rule?\n",
    "<br>\n",
    "<b style=\"background-color:red;color:white\">Question 8</b>: Which values have you decided to test at this stage? Why this range?\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "gen\tspecies\tstd      \tmin\tavg     \tmax     \tavg_hof \n",
      "1  \tsp1    \t0.0611531\t0  \t0.138622\t0.166667\t0.186582\n",
      "1  \tsp2    \t0.17997  \t0  \t0.142621\t0.571429\t0.413054\n",
      "2  \tsp1    \t0.010444 \t0.512821\t0.552687\t0.571429\t0.560847\n",
      "2  \tsp2    \t0.202134 \t0       \t0.225891\t0.571429\t0.560847\n",
      "3  \tsp1    \t0.0140812\t0.512821\t0.552852\t0.571429\t0.566799\n",
      "3  \tsp2    \t0.207369 \t0       \t0.238924\t0.571429\t0.56746 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-99c28286ccf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mmodel_train_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_rule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqty_of_rule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mmodel_train_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_per_rule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_per_rule_fix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mmodel_train_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Heig-VD/Semestre6/LFA/Projet_Maldives/libraries/model_train_cv.py\u001b[0m in \u001b[0;36mexecute_cv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mX_train_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0my_train_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainSystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Heig-VD/Semestre6/LFA/Projet_Maldives/libraries/model_train_cv.py\u001b[0m in \u001b[0;36mTrainSystem\u001b[0;34m(self, x_train, y_train, x_test, y_test, cv_number)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier_trefle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_max_vars_per_rule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_per_rule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier_trefle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sklearn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lfa_projet/lib/python3.7/site-packages/trefle/trefle_classifier.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         )\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_best_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_top_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lfa_projet/lib/python3.7/site-packages/trefle/evo/experiment/base/coco_experiment.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lfa_projet/lib/python3.7/site-packages/trefle/evo/experiment/base/coco_experiment.py\u001b[0m in \u001b[0;36mcoop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0mPOP_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mN_ELITE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hof\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m             )\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_logbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_species\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sp1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lfa_projet/lib/python3.7/site-packages/trefle/evo/experiment/base/coco_experiment.py\u001b[0m in \u001b[0;36mevolve_species\u001b[0;34m(all_species, species_name, other_species_representatives, CX_PROB, N_REPRESENTATIVES, POP_SIZE, N_ELITE, hof)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;31m# (4) Evaluate the entire population\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     evaluate_species(\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0moffspring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecies_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_species_representatives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_REPRESENTATIVES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m     )\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lfa_projet/lib/python3.7/site-packages/trefle/evo/experiment/base/coco_experiment.py\u001b[0m in \u001b[0;36mevaluate_species\u001b[0;34m(species, species_name, other_species_representatives, n_representatives, hof)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0mpartial_evaluate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecies_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     fitnesses = list(\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial_evaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_species_representatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m     )\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lfa_projet/lib/python3.7/site-packages/trefle/evo/experiment/base/coco_experiment.py\u001b[0m in \u001b[0;36meval_solution\u001b[0;34m(species_indices, ind_tuple)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mind_sp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mind_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspecies_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mind_sp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mind_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspecies_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coco_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind_sp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_sp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coco_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_y_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lfa_projet/lib/python3.7/site-packages/trefle/evo/experiment/coco/coco_individual.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, ind_tuple, X)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_native\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind_sp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_sp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mX_normed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lfa_projet/lib/python3.7/site-packages/trefle/evo/experiment/coco/native_coco_evaluator.py\u001b[0m in \u001b[0;36mpredict_native\u001b[0;34m(self, ind_sp1, ind_sp2, other_X)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_native\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_sp1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_sp2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_X\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mother_X\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind_sp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_sp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind_sp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_sp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "##############fitness function\n",
    "def fit (y_true, y_pred):\n",
    "    \n",
    "    y_pred_bin = round_to_cls(y_pred, n_classes=2)\n",
    "    tn, fp, fn, tp = libraries.trefle_project.getConfusionMatrixValues(y_true, y_pred_bin)\n",
    "\n",
    "    return libraries.measures_calculation.calculateF1(tn, fp, fn, tp)\n",
    "\n",
    "clf.fitness_function=fit\n",
    "###############\n",
    "\n",
    "#Path where you want to save yours models (you need to create the directory befor start the algorithm)\n",
    "path_save_results_directory = 'experiences/n_rules/'\n",
    "#file nam that will contain the results for each model create (so fo each fold)\n",
    "file_results_dv = 'values_number_of_rules.csv'\n",
    "#Name of the experience, this name will appear on the models files\n",
    "experience_value_name = 'exps_lab_lfa_number_of_rules'\n",
    "\n",
    "model_train_obj = ModelTrain(array_index_train_test = array_index_train_test,\n",
    "                             X_train = X_train,\n",
    "                             y_train = y_train, \n",
    "                             number_rule = 0, var_per_rule = 0, \n",
    "                             classifier_trefle = clf, \n",
    "                             path_save_results = path_save_results_directory,\n",
    "                            path_save_results_values=file_results_dv,\n",
    "                            experience_name = experience_value_name)\n",
    "\n",
    "\n",
    "#Here we can choose wich values for the number of rules and maximum variable per \n",
    "#rule we want to test along our experience ('here you need to change and explain your choice, on the repport')\n",
    "#--------------------\n",
    "rules_number_vec = [40, 60, 80]\n",
    "var_per_rule_fix = 10\n",
    "#--------------------\n",
    "\n",
    "for qty_of_rule in rules_number_vec:\n",
    "    model_train_obj.number_rule = qty_of_rule\n",
    "    model_train_obj.var_per_rule = var_per_rule_fix\n",
    "    model_train_obj.execute_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "#Plot sen spe resuts\n",
    "#read all csv\n",
    "#--------------------\n",
    "dataframe_results = pd.read_csv('values_number_of_rules.csv')\n",
    "#--------------------\n",
    "\n",
    "#dataframe_results_c = pd.read_csv('values_w.csv')\n",
    "dataframe_results.head()\n",
    "\n",
    "param_a_designation = 'nb of rules'\n",
    "param_b_designation = 'nb of var per rule'\n",
    "\n",
    "vec_measures = ['acc', 'f1', 'sen', 'spe']\n",
    "\n",
    "\n",
    "\n",
    "test_data = dataframe_results.iloc[:,0:2]\n",
    "\n",
    "\n",
    "data_frame_treated = libraries.trefle_project.treatmentResultsValues(dataframe_results, param_a_designation, param_b_designation, vec_measures)\n",
    "data_frame_treated.columns = ['N rule', 'N var per rule', 'acc', 'f1', 'sen', 'spe']\n",
    "display(data_frame_treated)\n",
    "\n",
    "\n",
    "\n",
    "libraries.interpretability_plots.plotSenSpeNRules(data_frame_treated, 'N rules')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finer search of parameters\n",
    "\n",
    "The next step will be to perform a grid search for both parameters on a narrow range of values. For this, we need to define ranges for them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"background-color:red;color:white\">Question 9</b>: On the base of the graphic above, select a narrower range for the number of rules to be explored in the next step. Justify your choice.\n",
    "<br>\n",
    "<b style=\"background-color:red;color:white\">Question 10</b>: Then, define a range of values for the number of variables per rule. How did you decide on them? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Var per rule and number of rules\n",
    "\n",
    "\n",
    "#--------------------\n",
    "#Path where you want to save yours models (you need to create the directory befor start the algorithm)\n",
    "path_save_results_directory = 'experiences/n_rules_nvar/'\n",
    "#file nam that will contain the results for each model create (so fo each fold)\n",
    "file_results_dv = 'values_number_of_rules_nvar.csv'\n",
    "#Name of the experience, this name will appear on the models files\n",
    "experience_value_name = 'exps_lab_lfa_number_of_rules_var'\n",
    "#--------------------\n",
    "\n",
    "\n",
    "model_train_obj = ModelTrain(array_index_train_test = array_index_train_test,\n",
    "                             X_train = X_train,\n",
    "                             y_train = y_train, \n",
    "                             number_rule = 0, var_per_rule = 0, \n",
    "                             classifier_trefle = clf, \n",
    "                             path_save_results = path_save_results_directory,\n",
    "                            path_save_results_values=file_results_dv,\n",
    "                            experience_name = experience_value_name)\n",
    "\n",
    "\n",
    "\n",
    "#Here we can choose wich values for the number of rules and maximum variable per \n",
    "#rule we want to test along our experience ('here you need to change and explain your choice, on the repport')\n",
    "#--------------------\n",
    "rules_number_vec = [2,4]\n",
    "var_per_rule_vec = [2,4,6,8]\n",
    "#--------------------\n",
    "\n",
    "for variation_a in rules_number_vec:\n",
    "    for variation_b in var_per_rule_vec:\n",
    "        model_train_obj.number_rule = variation_a\n",
    "        model_train_obj.var_per_rule = variation_b\n",
    "        model_train_obj.execute_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load models\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "\n",
    "#play with the results of the differents executions\n",
    "data = pd.read_csv(\"values_number_of_rules_nvar.csv\") \n",
    "# Preview the first 5 lines of the loaded data \n",
    "data.head()\n",
    "\n",
    "param_a_designation = 'nb of rules'\n",
    "param_b_designation = 'nb of var per rule'\n",
    "\n",
    "vec_measures = ['acc', 'f1', 'sen', 'spe']\n",
    "\n",
    "\n",
    "\n",
    "test_data = data.iloc[:,0:2]\n",
    "\n",
    "\n",
    "data_frame_treated = libraries.trefle_project.treatmentResultsValues(data, param_a_designation, param_b_designation, vec_measures)\n",
    "data_frame_treated.columns = ['N rule', 'N var per rule', 'acc', 'f1', 'sen', 'spe']\n",
    "display(data_frame_treated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize with 3D graphs\n",
    "Below you may visualize the performance of your models according to the explored paramaters: number of rules and number of variables per rule. You may change the code so as to make plots for different metrics (Acc, F1, Sen and Spe). You could also add new/different metrics by creating the corresponding method in the 'measures_calculation' class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot 3D\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "\n",
    "X = data_frame_treated['N rule']\n",
    "Y = data_frame_treated['N var per rule']\n",
    "Z = data_frame_treated['f1']\n",
    "\n",
    "y_axis_values = range(math.floor(min(Y)), math.ceil(max(Y))+1)\n",
    "x_axis_values = range(math.floor(min(X)), math.ceil(max(X))+1)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "surf = ax.plot_trisurf(X, Y, Z,  cmap=cm.YlGnBu, linewidth=0, antialiased=False)\n",
    "\n",
    "#ax.set_zlim(-1.01, 1.01)\n",
    "ax.set_xticks(x_axis_values, minor=False)\n",
    "ax.set_yticks(y_axis_values, minor=False)\n",
    "\n",
    "ax.set_xlabel('$Number of rules$')\n",
    "ax.set_ylabel('$Number of var per rule$')\n",
    "\n",
    "\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "\n",
    "\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.title('F1-Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"background-color:red;color:white\">Question 11</b> In your opinion, which values/ranges of both parameters: number of rules and vars per rule, should you choose to obtain the best models? (comment briefly on the plot and include it into to report)\n",
    "\n",
    "Don't forget to change those values below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional refinement of the parameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we observed the plot we can refine the search for parameter values. As for the previous experiment it is necessary to:\n",
    "<ul>\n",
    "    <li>define new values/ranges for the number of rules </li>\n",
    "    <li>define new values/ranges number of variable per rule </li>\n",
    "    <li>change the path name where you want to save the new models </li>\n",
    "    <li>change the name of the file that will contain the number of experiments</li>\n",
    "     \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Var per rule and number of rules\n",
    "\n",
    "\n",
    "#Change the path directory where you want to save the new results\n",
    "#--------------------\n",
    "#Path where you want to save yours models (you need to create the directory befor start the algorithm)\n",
    "path_save_results_directory = 'experiences/n_rules_nvar_tuning/'\n",
    "#file nam that will contain the results for each model create (so fo each fold)\n",
    "file_results_dv = 'values_number_of_rules_nvar_tuning.csv'\n",
    "#Name of the experience, this name will appear on the models files\n",
    "experience_value_name = 'exps_lab_lfa_number_of_rules_var_tuning'\n",
    "#--------------------\n",
    "\n",
    "\n",
    "model_train_obj = ModelTrain(array_index_train_test = array_index_train_test,\n",
    "                             X_train = X_train,\n",
    "                             y_train = y_train, \n",
    "                             number_rule = 0, var_per_rule = 0, \n",
    "                             classifier_trefle = clf, \n",
    "                             path_save_results = path_save_results_directory,\n",
    "                            path_save_results_values=file_results_dv,\n",
    "                            experience_name = experience_value_name)\n",
    "\n",
    "\n",
    "#Here we can choose wich values for the number of rules and maximum variable per \n",
    "#rule we want to test along our experience \n",
    "#('here you need to change and explain your choice, on the repport')\n",
    "#--------------------\n",
    "rules_number_vec = [2]\n",
    "var_per_rule_vec = [4]\n",
    "#--------------------\n",
    "\n",
    "for variation_a in rules_number_vec:\n",
    "    for variation_b in var_per_rule_vec:\n",
    "        model_train_obj.number_rule = variation_a\n",
    "        model_train_obj.var_per_rule = variation_b\n",
    "        model_train_obj.execute_cv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidating the results\n",
    "Now, put all yours models in the same directory (copy/past) and add all the csv results to the dataframe in order to analyse the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter sen/spe\n",
    "#read all csv\n",
    "dataframe_results = pd.read_csv('values_number_of_rules.csv')\n",
    "dataframe_results_b = pd.read_csv('values_number_of_rules_nvar.csv')\n",
    "dataframe_results_c = pd.read_csv('values_number_of_rules_nvar_tuning.csv')\n",
    "dataframe_results_d = pd.read_csv('values_rmse_weight_v2.csv')\n",
    "dataframe_results_e = pd.read_csv('values_sen_spe_weight.csv')\n",
    "\n",
    "dataframe_results_all = dataframe_results_b.append(dataframe_results)\n",
    "dataframe_results_all = dataframe_results_all.append(dataframe_results_c)\n",
    "dataframe_results_all = dataframe_results_all.append(dataframe_results_d)\n",
    "dataframe_results_all = dataframe_results_all.append(dataframe_results_e)\n",
    "\n",
    "#dataframe_results_c = pd.read_csv('values_w.csv')\n",
    "dataframe_results_all.columns = ['N rule', 'N var per rule','weight','CV number', 'tn', 'fp', 'fn', 'tp', 'file_name']\n",
    "dataframe_results_all = dataframe_results_all.reset_index(drop=True)\n",
    "display(dataframe_results_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have tested all the configurations, we have obtained a **large** number of models exhibiting diverse performance figures. At the end of a modeling process, the goal is to obtain one, or a few, models that would be deployed and used for new predictions. A selection process is thus necessary.\n",
    "\n",
    "A first selection is performed by applying a filter based on the diagnostic performance, thus reducing the number of models. Below you can see a scatter plot of all the models you obtained according to their sensitivity and specificity (as obtained on the validation subsets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot sent spe all\n",
    "\n",
    "#Plot all values\n",
    "#don't forget to turn off the others plotss\n",
    "vec_values_sen_spe_models = libraries.interpretability_methods.getSenSpeValuesByScores(dataframe_results_all)\n",
    "#vec_values_sen_spe_models = libraries.interpretability_methods.getSenSpeValuesByScores(data_frame_treated)\n",
    "\n",
    "plt.scatter(vec_values_sen_spe_models['Sensitivity'],vec_values_sen_spe_models['Specificity'],s=10, marker='o')\n",
    "\n",
    "plt.title('Threshold sen/spe')\n",
    "plt.xlabel('Sensitivity')\n",
    "plt.ylabel('Specificity')\n",
    "plt.savefig('ScatterPlot.png')\n",
    "\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "\n",
    "plt.show()\n",
    "print('You have {0} models'.format(len(vec_values_sen_spe_models)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First selection filter: based on sen/spe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having analysed the above performance overview of your models, you can apply a filter based on  sensitivity and specificity. In this way, only those models exhibiting better performance than some specified threshold will be selected for the next step.\n",
    "The plot below shows the effect of the combined thresholds on the number of models remaining after the filter is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot sen_spe  qty models 3D\n",
    "#that save x models\n",
    "%matplotlib notebook\n",
    "\n",
    "results_qty_models = libraries.interpretability_methods.plotSenSpeQtyModelsByThreshold(vec_values_sen_spe_models)\n",
    "\n",
    "#display(results_qty_models)\n",
    "\n",
    "X = results_qty_models['sensitivity']\n",
    "Y = results_qty_models['specificity']\n",
    "Z = results_qty_models['qty_models']\n",
    "\n",
    "#y_axis_values = range(math.floor(min(Y)), math.ceil(max(Y))+1)\n",
    "#x_axis_values = range(math.floor(min(X)), math.ceil(max(X))+1)\n",
    "\n",
    "max_quantity = results_qty_models.loc[results_qty_models['qty_models'].idxmax()]\n",
    "max_quantity = int(max_quantity['qty_models'])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "surf = ax.plot_trisurf(X, Y, Z.values,  cmap=cm.YlGnBu, linewidth=0, antialiased=False)\n",
    "\n",
    "#ax.set_zlim(0, max_quantity)\n",
    "ax.set_zticks(Z)\n",
    "#ax.set_xticks(x_axis_values, minor=False)\n",
    "#ax.set_yticks(y_axis_values, minor=False)\n",
    "\n",
    "ax.set_xlabel('$Sensitivity$')\n",
    "ax.set_ylabel('$Specificity$')\n",
    "\n",
    "\n",
    "\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
    "\n",
    "\n",
    "\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.title('Sen/Spe threshold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the base of this plot, you should decide on threshold values for both, specificity and sensitivity and apply them. The resulting subset of selected models is shown in the scatterplot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select values sen spe filtre\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "#Put a limit in sen/spe\n",
    "#Here you put the threshold for the sensitivity and specificity\n",
    "#Don't forget to shave the plot and comment into your repport\n",
    "#--------------------\n",
    "value_sensitivity = 0.8\n",
    "value_specificity = 0.8\n",
    "#--------------------\n",
    "\n",
    "\n",
    "#We apply them\n",
    "\n",
    "vec_values_sen_spe_models_filtered = libraries.interpretability_methods.filterDataframeBySenSpeLimit(value_sensitivity, value_specificity, vec_values_sen_spe_models)\n",
    "vec_values_sen_spe_models_filtered_invert = libraries.interpretability_methods.filterDataframeBySenSpeLimitContrary(value_sensitivity, value_specificity, vec_values_sen_spe_models)\n",
    "\n",
    "\n",
    "figure = libraries.interpretability_plots.plotDataFrameValuesFiltered(value_sensitivity, value_specificity,vec_values_sen_spe_models_filtered, vec_values_sen_spe_models_filtered_invert)\n",
    "\n",
    "\n",
    "print('You have {0} models'.format(len(vec_values_sen_spe_models_filtered)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"background-color:red;color:white\">Question 12</b>: Explain your choice of the threshold values for the sensitivity and specificity. (Save both plots into your reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Save the plot on the repport</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second selection: frequency-based filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a second model-selection filter is applied based on the \"importance\" of the features. Such feature importance is represented in this context by their relative presence (i.e. their frequency) among the models. \n",
    "\n",
    "#### Frequency of the variables\n",
    "The figure below shows the frequency of the variables among all the remaining models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "  \n",
    "    \n",
    "#--------------------\n",
    "list_models_path_complete = []\n",
    "for index, row in vec_values_sen_spe_models_filtered.iterrows():\n",
    "    model_path_complete = \"experiences/all_models/\" + str(row['file_name'])\n",
    "    list_models_path_complete.append(model_path_complete)\n",
    "#--------------------\n",
    "    \n",
    "#Perform the counting\n",
    "list_models_vars = libraries.interpretability_methods.transformModelsToModelVarObj(list_models_path_complete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot histogram before cut\n",
    "\n",
    "dict_values_resultant = libraries.interpretability_methods.countVarFreq(list_models_vars)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#indication of the number of models and variables\n",
    "qty_models = len(list_models_vars)\n",
    "qty_variables = len(dict_values_resultant)\n",
    "print(\"You have {0} models and {1} variables\".format(qty_models, qty_variables))\n",
    "\n",
    "#Plot the new histogram\n",
    "libraries.interpretability_plots.plotHistogramFreqVar(dict_values_resultant)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing a frequency threshold\n",
    "Filtering features by frequency will result in a reduction of both the number of features and the number of models, as models with eliminated variables are also eliminated. \n",
    "\n",
    "The plot below represents the number of models and variables that should remain after the filter is applied in function of the frequency threshold. It helps you to decide on which threshold to use for the filter.\n",
    "\n",
    "(Note that the frequency of a feature is calculated as the number of <b>different models</b> where it appears irrespective of the number of rules containing it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "#Perform the counting\n",
    "list_models_vars = libraries.interpretability_methods.transformModelsToModelVarObj(list_models_path_complete)\n",
    "dict_values = libraries.interpretability_methods.countVarFreq(list_models_vars)\n",
    "\n",
    "\n",
    "#TEST zone\n",
    "matrix_results = libraries.interpretability_methods.createPlotQtyVarPerModelByMinimumFreq(dict_values,list_models_vars)\n",
    "#display(matrix_results)\n",
    "#End test zone\n",
    "\n",
    "\n",
    "\n",
    "ax = plt.figure().gca()\n",
    "\n",
    "matrix_results.plot(kind='line',x='min freq var',y='number of models',ax=ax)\n",
    "matrix_results.plot(kind='line',x='min freq var',y='quantity of variables', color='red', ax=ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#libraries.interpretability_plots.plotFreqVarPerFreqMinimum(matrix_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on the plot above, select the minimum frequency (threshold) for the variables on your models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"background-color:red;color:white\">Question 13</b>: Explain your choice of the threshold. (Save both plots into your report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to indicate the name of the file where you want to save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valide the frequence value\n",
    "\n",
    "#Create a copy of the list that contains the model_var objects\n",
    "list_models_vars_cpopy = list_models_vars.copy()\n",
    "#select the minimum frequenty\n",
    "#-------------------\n",
    "nb_min_var = 35\n",
    "#--------------------\n",
    "\n",
    "#Perform the frequence\n",
    "list_model_var_resultant = libraries.interpretability_methods.reduceQtyVars(nb_min_var, dict_values,list_models_vars_cpopy)\n",
    "dict_values_resultant = libraries.interpretability_methods.countVarFreq(list_model_var_resultant)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#indication of the number of models and variables\n",
    "qty_models = len(list_model_var_resultant)\n",
    "qty_variables = len(dict_values_resultant)\n",
    "print(\"You have {0} models and {1} variables\".format(qty_models, qty_variables))\n",
    "\n",
    "#Plot the new histogram\n",
    "libraries.interpretability_plots.plotHistogramFreqVar(dict_values_resultant)\n",
    "#Show the frequency table\n",
    "dict_Values_ordered = libraries.interpretability_methods.sort_reverse_dictionary_by_values(dict_values_resultant)\n",
    "datafram_var_freq = pd.DataFrame(list(dict_Values_ordered.items()),columns=['Variable name','Frequence'])\n",
    "display(datafram_var_freq)\n",
    "\n",
    "\n",
    "#Perform the list of the models\n",
    "#--------------------\n",
    "file_name = 'models_selected.csv'\n",
    "#--------------------\n",
    "list_models_names=[model_var.model_path for model_var in list_model_var_resultant]\n",
    "dataframe_names_files = pd.DataFrame(list_models_names)\n",
    "dataframe_names_files.to_csv(file_name, sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carlos: Don't forget to save the plot resultant of your choice...\n",
    "<br>\n",
    "<b>The objective of the lab is to arrived at the end with 5-10 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analysis of the selected models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have selected the best models, they are saved on the file \"models_selected.CSV\" (Or other file if you change the name...)\n",
    "You may then load these models and use them to compute their predictions for the observations in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "# Import from file\n",
    "#--------------------\n",
    "fis = TrefleFIS.from_tff_file(\"experiences/all_models/exps_lab_lfa_number_of_rules_var_weigh_actual_1.0_conf_A_CV_0_rule_2_var_per_rule_6.ftt\")\n",
    "#--------------------\n",
    "# In the future, it could possible to call clf.predict_classes() directly\n",
    "# see issue #1\n",
    "y_pred_test = fis.predict(X_test)\n",
    "\n",
    "results_list_predictions = np.squeeze(np.asarray(y_pred_test))\n",
    "\n",
    "\n",
    "#libraries.results_plot.plotCMByTreflePredictions(y_test, results_list_predictions)\n",
    "#Convert your results into binary values\n",
    "results = []\n",
    "for element in y_pred_test:\n",
    "    if element > 0.5:\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)\n",
    "\n",
    "from libraries.ConfusionMatrix import ConfusionMatrix\n",
    "cm = confusion_matrix(y_test, results)\n",
    "n_classes = len(np.unique(y))\n",
    "ConfusionMatrix.plot(cm, classes=range(n_classes), title=\"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above is only an example of how to load models and test their performance in the test set. (Remember that the test set is the one who has not been used during the previous training/selectionn steps.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"background-color:red;color:white\">Question 14</span></b>: Among the final models, select three of them as follows: the smallest one (in terms of rules and variables), the best one (in terms of performance), and one in the \"middle\" that you consider as being a good trade-off between size and performance. With them:\n",
    "<ul>\n",
    "    <li>Apply them to the test set and analyze the results you obtained</li>\n",
    "    <li>Analyze them in terms of size, rules, vars per rules and other characteristics that you think are relevant</li>\n",
    "    <li>As far as possible, analyze their rules and try to \"explain\" their predictions.\n",
    "</ul>\n",
    "<br>\n",
    "Tips: You can use plots to described your results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
